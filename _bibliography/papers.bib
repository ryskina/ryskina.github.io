---
---

@inproceedings{queerai2023,
    abbr={FAccT},
    title={Queer In AI: A Case Study in Community-Led Participatory AI},
    author={Organizers {of} Queer {in} AI and Anaelia Ovalle and Arjun Subramonian and Ashwin Singh and 
            Claas Voelcker and Danica J. Sutherland and Davide Locatelli and
            Eva Breznik and Filip Klubička and Hang Yuan and Hetvi J and Huan Zhang and
            Jaidev Shriram and Kruno Lehman and Luca Soldaini and Maarten Sap and Marc Peter Deisenroth and 
            Maria Leonor Pacheco and Maria Ryskina and Martin Mundt and Anonymous and 
            Milind Agarwal and Nyx McLean and Pan Xu and A Pranav and Raj Korpan and Ruchira Ray and
            Sarah Mathew and Sarthak Arora and St John and Tanvi Anand and Vishakha Agrawal and 
            William Agnew and Yanan Long and Zijie J. Wang and Zeerak Talat and Avijit Ghosh and
            Nathaniel Dennler and Michael Noseworthy and Sharvani Jha and Emi Baylor and 
            Aditya Joshi and Natalia Y. Bilenko and Andrew McNamara and Raphael Gontijo-Lopes and
            Alex Markham and Evyn Dǒng and Jackie Kay and Manu Saraswat and Nikhil Vytla and Luke Stark},
    booktitle = {ACM Conference on Fairness, Accountability, and Transparency},
    abstract = {We present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community's programs over the years. We discuss different challenges that emerged in the process, look at ways this organization has fallen short of operationalizing participatory and intersectional principles, and then assess the organization's impact. Queer in AI provides important lessons and insights for practitioners and theorists of participatory methods broadly through its rejection of hierarchy in favor of decentralization, success at building aid and programs by and for the queer community, and effort to change actors and institutions outside of the queer community. Finally, we theorize how communities like Queer in AI contribute to the participatory design in AI more broadly by fostering cultures of participation in AI, welcoming and empowering marginalized participants, critiquing poor or exploitative participatory practices, and bringing participation to institutions outside of individual research projects. Queer in AI's work serves as a case study of grassroots activism and participatory methods within AI, demonstrating the potential of community-led participatory methods and intersectional praxis, while also providing challenges, case studies, and nuanced insights to researchers developing and using participatory methods.},
    arxiv={2303.16972},
    year={2023},
    display_authors = 1
}

@article{hupkes2022taxonomy,
  abbr={arXiv},
  title={State-of-the-art generalisation research in NLP: a taxonomy and review},
  author = {Dieuwke Hupkes and Mario Giulianelli and Verna Dankers and Mikel Artetxe and
          Yanai Elazar and Tiago Pimentel and Christos Christodoulopoulos and Karim Lasri and
          Naomi Saphra and Arabella Sinclair and Dennis Ulmer and Florian Schottmann and
          Khuyagbaatar Batsuren and Kaiser Sun and Koustuv Sinha and Leila Khalatbari and
          Maria Ryskina and Rita Frieske and Ryan Cotterell and Zhijing Jin},
  year={2022},
  journal = {arXiv preprint},
  arxiv="2210.03050",
  abstract="The ability to generalise well is one of the primary desiderata of natural language processing (NLP). Yet, what `good generalisation' entails and how it should be evaluated is not well understood, nor are there any common standards to evaluate it. In this paper, we aim to lay the ground-work to improve both of these issues. We present a taxonomy for characterising and understanding generalisation research in NLP, we use that taxonomy to present a comprehensive map of published generalisation studies, and we make recommendations for which areas might deserve attention in the future. Our taxonomy is based on an extensive literature review of generalisation research, and contains five axes along which studies can differ: their main motivation, the type of generalisation they aim to solve, the type of data shift they consider, the source by which this data shift is obtained, and the locus of the shift within the modelling pipeline. We use our taxonomy to classify over 400 previous papers that test generalisation, for a total of more than 600 individual experiments. Considering the results of this review, we present an in-depth analysis of the current state of generalisation research in NLP, and make recommendations for the future. Along with this paper, we release a webpage where the results of our review can be dynamically explored, and which we intend to up-date as new NLP generalisation studies are published. With this work, we aim to make steps towards making state-of-the-art generalisation testing the new status quo in NLP.",
  website={https://genbench.org/},
  display_authors = 3,
}

@phdthesis{ryskina-2022-thesis,
  abbr={Thesis},
  title = {Learning Computational Models of Non-Standard Language},
  author = {Maria Ryskina},
  school = {Carnegie Mellon University},
  year={2022},
  abstract = "Non-standard language such as novel words or creative spellings of existing ones often occurs in natural text corpora, posing significant challenges for natural language processing (NLP) models. While humans can successfully infer the meaning communicated in such non-standard ways, NLP models largely discard linguistic innovation as noise, ignoring its fundamentally non-random nature and losing valuable context. In this thesis, we focus on computational modeling of such creative phenomena, aiming to both improve the automatic processing of non-standardized text data and to learn more about the linguistic and cognitive factors that allow humans to produce and understand novel linguistic items. We present empirical studies of several phenomena under the umbrella of non-standard language, characterized in terms of different linguistic units (orthographic, morphological, or lexical) and considered at different levels of granularity (from individual users to entire dialects or languages). First, we show how idiosyncratic spelling preferences reveal information about the user, with an application to the bibliographic task of identifying typesetters of historical printed documents. Second, we discuss the common patterns in user-specific orthographies and demonstrate that incorporating these patterns helps with unsupervised conversion of idiosyncratically romanized text into the language's native orthography. Third, we consider word emergence in a dialect or language as a whole and, in two diachronic corpora studies, model the language-internal and language-external factors that drive it. Finally, we look at how continuous emergence of novel words is reconciled with the existing system of morphological rules, focusing on generalization to unseen lemmas in morphological inflection in several languages.",
  pdf="https://www.lti.cs.cmu.edu/sites/default/files/ryskina%2C%20maria%20-%20CMU-LTI-22-019.pdf"
}

@inproceedings{batsuren-etal-2022-unimorph,
    abbr={LREC},
    title = "{U}ni{M}orph 4.0: {U}niversal {M}orphology",
    author = "Batsuren, Khuyagbaatar  and
      Goldman, Omer  and
      Khalifa, Salam  and
      Habash, Nizar  and
      Kiera{\'s}, Witold  and
      Bella, G{\'a}bor  and
      Leonard, Brian  and
      Nicolai, Garrett  and
      Gorman, Kyle  and
      Ate, Yustinus Ghanggo  and
      Ryskina, Maria  and
      Mielke, Sabrina  and
      Budianskaya, Elena  and
      El-Khaissi, Charbel  and
      Pimentel, Tiago  and
      Gasser, Michael  and
      Lane, William Abbott  and
      Raj, Mohit  and
      Coler, Matt  and
      Samame, Jaime Rafael Montoya  and
      Camaiteri, Delio Siticonatzi  and
      Rojas, Esa{\'u} Zumaeta  and
      L{\'o}pez Francis, Didier  and
      Oncevay, Arturo  and
      L{\'o}pez Bautista, Juan  and
      Villegas, Gema Celeste Silva  and
      Hennigen, Lucas Torroba  and
      Ek, Adam  and
      Guriel, David  and
      Dirix, Peter  and
      Bernardy, Jean-Philippe  and
      Scherbakov, Andrey  and
      Bayyr-ool, Aziyana  and
      Anastasopoulos, Antonios  and
      Zariquiey, Roberto  and
      Sheifer, Karina  and
      Ganieva, Sofya  and
      Cruz, Hilaria  and
      Karah{\'o}{\v{g}}a, Ritv{\'a}n  and
      Markantonatou, Stella  and
      Pavlidis, George  and
      Plugaryov, Matvey  and
      Klyachko, Elena  and
      Salehi, Ali  and
      Angulo, Candy  and
      Baxi, Jatayu  and
      Krizhanovsky, Andrew  and
      Krizhanovskaya, Natalia  and
      Salesky, Elizabeth  and
      Vania, Clara  and
      Ivanova, Sardana  and
      White, Jennifer  and
      Maudslay, Rowan Hall  and
      Valvoda, Josef  and
      Zmigrod, Ran  and
      Czarnowska, Paula  and
      Nikkarinen, Irene  and
      Salchak, Aelita  and
      Bhatt, Brijesh  and
      Straughn, Christopher  and
      Liu, Zoey  and
      Washington, Jonathan North  and
      Pinter, Yuval  and
      Ataman, Duygu  and
      Wolinski, Marcin  and
      Suhardijanto, Totok  and
      Yablonskaya, Anna  and
      Stoehr, Niklas  and
      Dolatian, Hossep  and
      Nuriah, Zahroh  and
      Ratan, Shyam  and
      Tyers, Francis M.  and
      Ponti, Edoardo M.  and
      Aiton, Grant  and
      Arora, Aryaman  and
      Hatcher, Richard J.  and
      Kumar, Ritesh  and
      Young, Jeremiah  and
      Rodionova, Daria  and
      Yemelina, Anastasia  and
      Andrushko, Taras  and
      Marchenko, Igor  and
      Mashkovtseva, Polina  and
      Serova, Alexandra  and
      Prud{'}hommeaux, Emily  and
      Nepomniashchaya, Maria  and
      Giunchiglia, Fausto  and
      Chodroff, Eleanor  and
      Hulden, Mans  and
      Silfverberg, Miikka  and
      McCarthy, Arya D.  and
      Yarowsky, David  and
      Cotterell, Ryan  and
      Tsarfaty, Reut  and
      Vylomova, Ekaterina",
    booktitle = "Proc. Language Resources and Evaluation Conference",
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.89",
    pages = "840--855",
    abstract = "The Universal Morphology (UniMorph) project is a collaborative effort providing broad-coverage instantiated normalized morphological inflection tables for hundreds of diverse world languages. The project comprises two major thrusts: a language-independent feature schema for rich morphological annotation, and a type-level resource of annotated data in diverse languages realizing that schema. This paper presents the expansions and improvements on several fronts that were made in the last couple of years (since McCarthy et al. (2020)). Collaborative efforts by numerous linguists have added 66 new languages, including 24 endangered languages. We have implemented several improvements to the extraction pipeline to tackle some issues, e.g., missing gender and macrons information. We have amended the schema to use a hierarchical structure that is needed for morphological phenomena like multiple-argument agreement and case stacking, while adding some missing morphological features to make the schema more inclusive.In light of the last UniMorph release, we also augmented the database with morpheme segmentation for 16 languages. Lastly, this new release makes a push towards inclusion of derivational morphology in UniMorph by enriching the data and annotation schema with instances representing derivational processes from MorphyNet.",
    supp="https://github.com/unimorph",
    pdf = "https://aclanthology.org/2022.lrec-1.89",
    display_authors = 2,
    equal = true,
}

@article{10.1145/3538543,
    abbr = {XRDS},
    author = {Jethwani, Hetvi and Subramonian, Arjun and Agnew, William and Bleile, MaryLena and Arora, Sarthak and Ryskina, Maria and Xiong, Jeffrey},
    title = {Queer in AI},
    year = {2022},
    issue_date = {Summer 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {28},
    number = {4},
    issn = {1528-4972},
    url = {https://doi.org/10.1145/3538543},
    doi = {10.1145/3538543},
    abstract = {Queer in AI is an organization that aims to combat the harms faced by queer researchers within AI. Several inclusion initiatives are outlined, including those centered on policy and financial aid.},
    journal = {XRDS: Crossroads, The ACM Magazine for Students},
    pages = {18--21},
    numpages = {4},
    pdf = {https://dl.acm.org/doi/10.1145/3538543},
    display_authors = 3
}

@inproceedings{ryskina-knight-2021-learning,
    abbr={BlackboxNLP},
    title = "Learning Mathematical Properties of Integers",
    author = "Ryskina, Maria  and
      Knight, Kevin",
    booktitle = "Proc. BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.blackboxnlp-1.30",
    doi = "10.18653/v1/2021.blackboxnlp-1.30",
    pages = "389--395",
    abstract = "Embedding words in high-dimensional vector spaces has proven valuable in many natural language applications. In this work, we investigate whether similarly-trained embeddings of integers can capture concepts that are useful for mathematical applications. We probe the integer embeddings for mathematical knowledge, apply them to a set of numerical reasoning tasks, and show that by learning the representations from mathematical sequence data, we can substantially improve over number embeddings learned from English text corpora.",
    supp = "https://github.com/ryskina/integer-embedding-tests",
    poster={Ryskina-Knight-2021-integers-poster.pdf},
    pdf = "https://aclanthology.org/2021.blackboxnlp-1.30",
}

@inproceedings{pimentel-ryskina-etal-2021-sigmorphon,
    abbr={SIGMORPHON},
    title = "{SIGMORPHON} 2021 Shared Task on Morphological Reinflection: Generalization Across Languages",
    author = "Pimentel, Tiago  and
      Ryskina, Maria  and
      Mielke, Sabrina J.  and
      Wu, Shijie  and
      Chodroff, Eleanor  and
      Leonard, Brian  and
      Nicolai, Garrett  and
      Ghanggo Ate, Yustinus  and
      Khalifa, Salam  and
      Habash, Nizar  and
      El-Khaissi, Charbel  and
      Goldman, Omer  and
      Gasser, Michael  and
      Lane, William  and
      Coler, Matt  and
      Oncevay, Arturo  and
      Montoya Samame, Jaime Rafael  and
      Silva Villegas, Gema Celeste  and
      Ek, Adam  and
      Bernardy, Jean-Philippe  and
      Shcherbakov, Andrey  and
      Bayyr-ool, Aziyana  and
      Sheifer, Karina  and
      Ganieva, Sofya  and
      Plugaryov, Matvey  and
      Klyachko, Elena  and
      Salehi, Ali  and
      Krizhanovsky, Andrew  and
      Krizhanovsky, Natalia  and
      Vania, Clara  and
      Ivanova, Sardana  and
      Salchak, Aelita  and
      Straughn, Christopher  and
      Liu, Zoey  and
      Washington, Jonathan North  and
      Ataman, Duygu  and
      Kiera{\'s}, Witold  and
      Woli{\'n}ski, Marcin  and
      Suhardijanto, Totok  and
      Stoehr, Niklas  and
      Nuriah, Zahroh  and
      Ratan, Shyam  and
      Tyers, Francis M.  and
      Ponti, Edoardo M.  and
      Aiton, Grant  and
      Hatcher, Richard J.  and
      Prud{'}hommeaux, Emily  and
      Kumar, Ritesh  and
      Hulden, Mans  and
      Barta, Botond  and
      Lakatos, Dorina  and
      Szolnok, G{\'a}bor  and
      {\'A}cs, Judit  and
      Raj, Mohit  and
      Yarowsky, David  and
      Cotterell, Ryan  and
      Ambridge, Ben  and
      Vylomova, Ekaterina",
    booktitle = "Proc. SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology",
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.sigmorphon-1.25",
    doi = "10.18653/v1/2021.sigmorphon-1.25",
    pages = "229--259",
    abstract = "This year's iteration of the SIGMORPHON Shared Task on morphological reinflection focuses on typological diversity and cross-lingual variation of morphosyntactic features. In terms of the task, we enrich UniMorph with new data for 32 languages from 13 language families, with most of them being under-resourced: Kunwinjku, Classical Syriac, Arabic (Modern Standard, Egyptian, Gulf), Hebrew, Amharic, Aymara, Magahi, Braj, Kurdish (Central, Northern, Southern), Polish, Karelian, Livvi, Ludic, Veps, V{\~o}ro, Evenki, Xibe, Tuvan, Sakha, Turkish, Indonesian, Kodi, Seneca, Ash{\'a}ninka, Yanesha, Chukchi, Itelmen, Eibela. We evaluate six systems on the new data and conduct an extensive error analysis of the systems' predictions. Transformer-based models generally demonstrate superior performance on the majority of languages, achieving {\textgreater}90{\%} accuracy on 65{\%} of them. The languages on which systems yielded low accuracy are mainly under-resourced, with a limited amount of data. Most errors made by the systems are due to allomorphy, honorificity, and form variation. In addition, we observe that systems especially struggle to inflect multiword lemmas. The systems also produce misspelled forms or end up in repetitive loops (e.g., RNN-based models). Finally, we report a large drop in systems' performance on previously unseen lemmas.",
    pdf = "https://aclanthology.org/2021.sigmorphon-1.25",
    supp = "https://github.com/sigmorphon/2021Task0",
    display_authors = 2,
    equal = true,
}

@inproceedings{ryskina-etal-2021-comparative,
    abbr={SIGMORPHON},
    title = "Comparative Error Analysis in Neural and Finite-state Models for Unsupervised Character-level Transduction",
    author = "Ryskina, Maria  and
      Hovy, Eduard  and
      Berg-Kirkpatrick, Taylor  and
      Gormley, Matthew R.",
    booktitle = "Proc. SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology",
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.sigmorphon-1.22",
    doi = "10.18653/v1/2021.sigmorphon-1.22",
    pages = "198--211",
    abstract = "Traditionally, character-level transduction problems have been solved with finite-state models designed to encode structural and linguistic knowledge of the underlying process, whereas recent approaches rely on the power and flexibility of sequence-to-sequence models with attention. Focusing on the less explored unsupervised learning scenario, we compare the two model classes side by side and find that they tend to make different types of errors even when achieving comparable performance. We analyze the distributions of different error classes using two unsupervised tasks as testbeds: converting informally romanized text into the native script of its language (for Russian, Arabic, and Kannada) and translating between a pair of closely related languages (Serbian and Bosnian). Finally, we investigate how combining finite-state and sequence-to-sequence models at decoding time affects the output quantitatively and qualitatively.",
    slides={Ryskina-etal-2021-error-analysis-slides.pdf},
    talk={https://youtu.be/ijwOF0fpqMs},
}

@inproceedings{ravichander-etal-2021-noiseqa,
    abbr={EACL},
    title = "{N}oise{QA}: Challenge Set Evaluation for User-Centric Question Answering",
    author = "Ravichander, Abhilasha  and
      Dalmia, Siddharth  and
      Ryskina, Maria  and
      Metze, Florian  and
      Hovy, Eduard  and
      Black, Alan W",
    booktitle = "Proc. European Chapter of the Association for Computational Linguistics",
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.259",
    doi = "10.18653/v1/2021.eacl-main.259",
    pages = "2976--2992",
    abstract = "When Question-Answering (QA) systems are deployed in the real world, users query them through a variety of interfaces, such as speaking to voice assistants, typing questions into a search engine, or even translating questions to languages supported by the QA system. While there has been significant community attention devoted to identifying correct answers in passages assuming a perfectly formed question, we show that components in the pipeline that precede an answering engine can introduce varied and considerable sources of error, and performance can degrade substantially based on these upstream noise sources even for powerful pre-trained QA models. We conclude that there is substantial room for progress before QA systems can be effectively deployed, highlight the need for QA evaluation to expand to consider real-world use, and hope that our findings will spur greater community interest in the issues that arise when our systems actually need to be of utility to humans.",
    pdf = "https://aclanthology.org/2021.eacl-main.259",
    website={https://noiseqa.github.io/},
}

@article{arkhangorodsky-2021-selfplay,
    abbr={arXiv},
    title = {Two Approaches to Building Collaborative, Task-Oriented Dialog Agents through Self-Play},
    author = {Arkady Arkhangorodsky and Scot Fang and Victoria Knight and Ajay Nagesh and Maria Ryskina and Kevin Knight},
    journal = {arXiv preprint},
    year={2021},
    abstract="Task-oriented dialog systems are often trained on human/human dialogs, such as collected from Wizard-of-Oz interfaces. However, human/human corpora are frequently too small for supervised training to be effective. This paper investigates two approaches to training agent-bots and user-bots through self-play, in which they autonomously explore an API environment, discovering communication strategies that enable them to solve the task. We give empirical results for both reinforcement learning and game-theoretic equilibrium finding.",
    arxiv="2109.09597"
}

@inproceedings{ryskina-etal-2020-phonetic,
    abbr={ACL},
    title = "Phonetic and Visual Priors for Decipherment of Informal {R}omanization",
    author = "Ryskina, Maria  and
      Gormley, Matthew R.  and
      Berg-Kirkpatrick, Taylor",
    booktitle = "Proc. Association for Computational Linguistics",
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.737",
    doi = "10.18653/v1/2020.acl-main.737",
    pages = "8308--8319",
    abstract = "Informal romanization is an idiosyncratic process used by humans in informal digital communication to encode non-Latin script languages into Latin character sets found on common keyboards. Character substitution choices differ between users but have been shown to be governed by the same main principles observed across a variety of languages{---}namely, character pairs are often associated through phonetic or visual similarity. We propose a noisy-channel WFST cascade model for deciphering the original non-Latin script from observed romanized text in an unsupervised fashion. We train our model directly on romanized data from two languages: Egyptian Arabic and Russian. We demonstrate that adding inductive bias through phonetic and visual priors on character mappings substantially improves the model{'}s performance on both languages, yielding results much closer to the supervised skyline. Finally, we introduce a new dataset of romanized Russian, collected from a Russian social network website and partially annotated for our experiments.",
    arxiv={2005.02517},
    slides={Ryskina-etal-2020-romanization-slides.pdf},
    supp={https://github.com/ryskina/romanization-decipherment},
    talk={https://slideslive.com/38929400/phonetic-and-visual-priors-for-decipherment-of-informal-romanization},
    selected={true},
}

@inproceedings{ryskina-etal-2020-new,
    abbr={SCiL},
    title = "Where New Words Are Born: Distributional Semantic Analysis of Neologisms and Their Semantic Neighborhoods",
    author = "Ryskina, Maria  and
      Rabinovich, Ella  and
      Berg-Kirkpatrick, Taylor  and
      Mortensen, David R.  and
      Tsvetkov, Yulia",
    booktitle = "Proc. Society for Computation in Linguistics",
    year = "2020",
    address = "New York, New York",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.scil-1.43",
    pages = "367--376",
    abstract = "We perform statistical analysis of the phenomenon of neology, the process by which new words emerge in a language, using large diachronic corpora of English. We investigate the importance of two factors, semantic sparsity and frequency growth rates of semantic neighbors, formalized in the distributional semantics paradigm. We show that both factors are predictive of word emergence although we find more support for the latter hypothesis. Besides presenting a new linguistic application of distributional semantics, this study tackles the linguistic question of the role of language-internal factors (in our case, sparsity) in language change motivated by language-external factors (reflected in frequency growth).",
    poster={Ryskina-etal-2020-neology-poster.pdf},
    supp={https://github.com/ryskina/neology},
    pdf = "https://aclanthology.org/2020.scil-1.43",
    selected={true},
}

@inproceedings{opera-2019,
    abbr={TAC},
    title={OPERA: Operations-oriented Probabilistic Extraction, Reasoning, and Analysis},
    author={Hovy, Eduard and 
      Carbonell, Jaime and 
      Chalupsky, Hans and
      Gershman, Anatole and 
      Hauptmann, Alex and 
      Metze, Florian and 
      Mitamura, Teruko and 
      Sheikh, Zaid and 
      Dangi, Ankit and 
      Chaudhary, Aditi and
      Chen, Xianyang and 
      Kong, Xiang and 
      Huang, Bernie and 
      Medina, Salvador and 
      Liu, Hector and 
      Ma, Xuezhe and 
      Ryskina, Maria and 
      Sanabria, Ramon and
      Gangal, Varun},
    booktitle={Proc. Text Analysis Conference},
    year={2019},
    abstract = "The OPERA system of CMU and USC/ISI performs end-to-end information extraction from multiple media and languages (English, Russian, Ukrainian), integrates the results, builds Knowledge Bases about the domain, and does hypothesis creation and reasoning to answer questions.",
    pdf={https://tac.nist.gov/publications/2019/participant.papers/TAC2019.OPERA.proceedings.pdf},
    display_authors = 2,
}

@inproceedings{ryskina-etal-2017-automatic,
    abbr={ACL},
    title = "Automatic Compositor Attribution in the First Folio of Shakespeare",
    author = "Ryskina, Maria  and
      Alpert-Abrams, Hannah  and
      Garrette, Dan  and
      Berg-Kirkpatrick, Taylor",
    booktitle = "Proc. Association for Computational Linguistics",
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-2065",
    doi = "10.18653/v1/P17-2065",
    pages = "411--416",
    abstract = "Compositor attribution, the clustering of pages in a historical printed document by the individual who set the type, is a bibliographic task that relies on analysis of orthographic variation and inspection of visual details of the printed page. In this paper, we introduce a novel unsupervised model that jointly describes the textual and visual features needed to distinguish compositors. Applied to images of Shakespeare{'}s First Folio, our model predicts attributions that agree with the manual judgements of bibliographers with an accuracy of 87%, even on text that is the output of OCR.",
    poster={https://www.aclweb.org/anthology/attachments/P17-2065.Poster.pdf},
    pdf = "https://aclanthology.org/P17-2065",
}
