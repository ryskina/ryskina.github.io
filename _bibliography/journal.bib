@article{hupkes2022taxonomy,
  abbr={Nat Mach Intell},
  title={A taxonomy and review of generalization research in NLP},
  author = {Dieuwke Hupkes and Mario Giulianelli and Verna Dankers and Mikel Artetxe and
          Yanai Elazar and Tiago Pimentel and Christos Christodoulopoulos and Karim Lasri and
          Naomi Saphra and Arabella Sinclair and Dennis Ulmer and Florian Schottmann and
          Khuyagbaatar Batsuren and Kaiser Sun and Koustuv Sinha and Leila Khalatbari and
          Maria Ryskina and Rita Frieske and Ryan Cotterell and Zhijing Jin},
  year={2023},
  journal = {Nature Machine Intelligence},
  arxiv="2210.03050",
  pdf="https://www.nature.com/articles/s42256-023-00729-y",
  abstract="The ability to generalize well is one of the primary desiderata for models of natural language processing (NLP), but what ‘good generalization’ entails and how it should be evaluated is not well understood. In this Analysis we present a taxonomy for characterizing and understanding generalization research in NLP. The proposed taxonomy is based on an extensive literature review and contains five axes along which generalization studies can differ: their main motivation, the type of generalization they aim to solve, the type of data shift they consider, the source by which this data shift originated, and the locus of the shift within the NLP modelling pipeline. We use our taxonomy to classify over 700 experiments, and we use the results to present an in-depth analysis that maps out the current state of generalization research in NLP and make recommendations for which areas deserve attention in the future.",
  website={https://genbench.org/},
  display_authors = 3,
}


@article{ivanova2025elements,
    abbr={TACL},
    author    = {Ivanova, Anna and Sathe, Aalok and Lipkin, Benjamin and Kumar, Unnathi and Radkani,
                Setayesh and Clark, Thomas H and Kauf, Carina and Hu, Jennifer and RT, Pramod and
                Grand, Gabriel and Paulun, Vivian and Ryskina, Maria and Akyurek, Ekin and Wilcox,
                Ethan and Rashid, Nafisa and Choshen, Leshem and Levy, Roger and Fedorenko, Evelina
                and Tenenbaum, Josh and Andreas, Jacob},
    title     = {Elements of World Knowledge (EWoK): A cognition-inspired framework for evaluating
                basic world knowledge in language models},
    journal   = {Accepted to Transaction of the Association for Computational Linguistics},
    year      = {2025},
    abstract="The ability to build and leverage world models is essential for a general-purpose AI agent. Testing such capabilities is hard, in part because the building blocks of world models are ill-defined. We present Elements of World Knowledge (EWOK), a framework for evaluating world modeling in language models by testing their ability to use knowledge of a concept to match a target text with a plausible/implausible context. EWOK targets specific concepts from multiple knowledge domains known to be vital for world modeling in humans. Domains range from social interactions (help/hinder) to spatial relations (left/right). Both, contexts and targets are minimal pairs. Objects, agents, and locations in the items can be flexibly filled in enabling easy generation of multiple controlled datasets. We then introduce EWOK-CORE-1.0, a dataset of 4,374 items covering 11 world knowledge domains. We evaluate 20 openweights large language models (1.3B--70B parameters) across a battery of evaluation paradigms along with a human norming study comprising 12,480 measurements. The overall performance of all tested models is worse than human performance, with results varying drastically across domains. These data highlight simple cases where even large models fail and present rich avenues for targeted research on LLM world modeling capabilities.",
    arxiv="2405.09605v1",
    website={https://ewok-core.github.io/},
    display_authors = 3,
    equal = true,
}