@article{ivanova2024elements,
    abbr={arXiv},
    author    = {Ivanova, Anna and Sathe, Aalok and Lipkin, Benjamin and Kumar, Unnathi and Radkani,
                Setayesh and Clark, Thomas H and Kauf, Carina and Hu, Jennifer and RT, Pramod and
                Grand, Gabriel and Paulun, Vivian and Ryskina, Maria and Akyurek, Ekin and Wilcox,
                Ethan and Rashid, Nafisa and Choshen, Leshem and Levy, Roger and Fedorenko, Evelina
                and Tenenbaum, Josh and Andreas, Jacob},
    title     = {Elements of World Knowledge (EWoK): A cognition-inspired framework for evaluating
                basic world knowledge in language models},
    journal   = {arXiv preprint},
    year      = {2024},
    abstract="The ability to build and leverage world models is essential for a general-purpose AI agent. Testing such capabilities is hard, in part because the building blocks of world models are ill-defined. We present Elements of World Knowledge (EWOK), a framework for evaluating world modeling in language models by testing their ability to use knowledge of a concept to match a target text with a plausible/implausible context. EWOK targets specific concepts from multiple knowledge domains known to be vital for world modeling in humans. Domains range from social interactions (help/hinder) to spatial relations (left/right). Both, contexts and targets are minimal pairs. Objects, agents, and locations in the items can be flexibly filled in enabling easy generation of multiple controlled datasets. We then introduce EWOK-CORE-1.0, a dataset of 4,374 items covering 11 world knowledge domains. We evaluate 20 openweights large language models (1.3B--70B parameters) across a battery of evaluation paradigms along with a human norming study comprising 12,480 measurements. The overall performance of all tested models is worse than human performance, with results varying drastically across domains. These data highlight simple cases where even large models fail and present rich avenues for targeted research on LLM world modeling capabilities.",
    arxiv="2405.09605v1",
    website={https://ewok-core.github.io/},
    display_authors = 3,
    equal = true,
}

@article{arkhangorodsky-2021-selfplay,
    abbr={arXiv},
    title = {Two Approaches to Building Collaborative, Task-Oriented Dialog Agents through Self-Play},
    author = {Arkady Arkhangorodsky and Scot Fang and Victoria Knight and Ajay Nagesh and Maria Ryskina and Kevin Knight},
    journal = {arXiv preprint},
    year={2021},
    abstract="Task-oriented dialog systems are often trained on human/human dialogs, such as collected from Wizard-of-Oz interfaces. However, human/human corpora are frequently too small for supervised training to be effective. This paper investigates two approaches to training agent-bots and user-bots through self-play, in which they autonomously explore an API environment, discovering communication strategies that enable them to solve the task. We give empirical results for both reinforcement learning and game-theoretic equilibrium finding.",
    arxiv="2109.09597"
}

@article{10.1145/3538543,
    abbr = {XRDS},
    author = {Jethwani, Hetvi and Subramonian, Arjun and Agnew, William and Bleile, MaryLena and Arora, Sarthak and Ryskina, Maria and Xiong, Jeffrey},
    title = {Queer in AI},
    year = {2022},
    issue_date = {Summer 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {28},
    number = {4},
    issn = {1528-4972},
    url = {https://doi.org/10.1145/3538543},
    doi = {10.1145/3538543},
    abstract = {Queer in AI is an organization that aims to combat the harms faced by queer researchers within AI. Several inclusion initiatives are outlined, including those centered on policy and financial aid.},
    journal = {XRDS: Crossroads, The ACM Magazine for Students},
    pages = {18--21},
    numpages = {4},
    pdf = {https://dl.acm.org/doi/10.1145/3538543},
    display_authors = 3
}