@article{hupkes2022taxonomy,
  abbr={arXiv},
  title={State-of-the-art generalisation research in NLP: a taxonomy and review},
  author = {Dieuwke Hupkes and Mario Giulianelli and Verna Dankers and Mikel Artetxe and
          Yanai Elazar and Tiago Pimentel and Christos Christodoulopoulos and Karim Lasri and
          Naomi Saphra and Arabella Sinclair and Dennis Ulmer and Florian Schottmann and
          Khuyagbaatar Batsuren and Kaiser Sun and Koustuv Sinha and Leila Khalatbari and
          Maria Ryskina and Rita Frieske and Ryan Cotterell and Zhijing Jin},
  year={2022},
  journal = {arXiv preprint},
  arxiv="2210.03050",
  abstract="The ability to generalise well is one of the primary desiderata of natural language processing (NLP). Yet, what `good generalisation' entails and how it should be evaluated is not well understood, nor are there any common standards to evaluate it. In this paper, we aim to lay the ground-work to improve both of these issues. We present a taxonomy for characterising and understanding generalisation research in NLP, we use that taxonomy to present a comprehensive map of published generalisation studies, and we make recommendations for which areas might deserve attention in the future. Our taxonomy is based on an extensive literature review of generalisation research, and contains five axes along which studies can differ: their main motivation, the type of generalisation they aim to solve, the type of data shift they consider, the source by which this data shift is obtained, and the locus of the shift within the modelling pipeline. We use our taxonomy to classify over 400 previous papers that test generalisation, for a total of more than 600 individual experiments. Considering the results of this review, we present an in-depth analysis of the current state of generalisation research in NLP, and make recommendations for the future. Along with this paper, we release a webpage where the results of our review can be dynamically explored, and which we intend to up-date as new NLP generalisation studies are published. With this work, we aim to make steps towards making state-of-the-art generalisation testing the new status quo in NLP.",
  website={https://genbench.org/},
  display_authors = 3,
}

@article{arkhangorodsky-2021-selfplay,
    abbr={arXiv},
    title = {Two Approaches to Building Collaborative, Task-Oriented Dialog Agents through Self-Play},
    author = {Arkady Arkhangorodsky and Scot Fang and Victoria Knight and Ajay Nagesh and Maria Ryskina and Kevin Knight},
    journal = {arXiv preprint},
    year={2021},
    abstract="Task-oriented dialog systems are often trained on human/human dialogs, such as collected from Wizard-of-Oz interfaces. However, human/human corpora are frequently too small for supervised training to be effective. This paper investigates two approaches to training agent-bots and user-bots through self-play, in which they autonomously explore an API environment, discovering communication strategies that enable them to solve the task. We give empirical results for both reinforcement learning and game-theoretic equilibrium finding.",
    arxiv="2109.09597"
}

@article{10.1145/3538543,
    abbr = {XRDS},
    author = {Jethwani, Hetvi and Subramonian, Arjun and Agnew, William and Bleile, MaryLena and Arora, Sarthak and Ryskina, Maria and Xiong, Jeffrey},
    title = {Queer in AI},
    year = {2022},
    issue_date = {Summer 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {28},
    number = {4},
    issn = {1528-4972},
    url = {https://doi.org/10.1145/3538543},
    doi = {10.1145/3538543},
    abstract = {Queer in AI is an organization that aims to combat the harms faced by queer researchers within AI. Several inclusion initiatives are outlined, including those centered on policy and financial aid.},
    journal = {XRDS: Crossroads, The ACM Magazine for Students},
    pages = {18--21},
    numpages = {4},
    pdf = {https://dl.acm.org/doi/10.1145/3538543},
    display_authors = 3
}